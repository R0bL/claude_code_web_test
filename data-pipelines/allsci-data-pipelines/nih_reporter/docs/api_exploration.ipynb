{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIH RePORTER API v2 - Exploration Notebook\n",
    "\n",
    "This notebook documents the exploration of the NIH RePORTER API v2 to understand the complete response schema and design the data pipeline.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Test API connectivity and authentication\n",
    "2. Discover all available fields in the response\n",
    "3. Understand nested structures and data types\n",
    "4. Test pagination and rate limiting\n",
    "5. Document field mappings for pipeline design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. API Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "API_BASE_URL = 'https://api.reporter.nih.gov'\n",
    "API_ENDPOINT = '/v2/projects/search'\n",
    "RATE_LIMIT_DELAY = 1.0  # seconds between requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic API Test - Small Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a very small query to get complete field structure\n",
    "test_payload = {\n",
    "    'criteria': {\n",
    "        'fiscal_years': [2024],\n",
    "        'agencies': ['NCI']  # Narrow down to get faster response\n",
    "    },\n",
    "    'offset': 0,\n",
    "    'limit': 5  # Just 5 records to see structure\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f'{API_BASE_URL}{API_ENDPOINT}',\n",
    "    json=test_payload,\n",
    "    headers={'Content-Type': 'application/json'}\n",
    ")\n",
    "\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "data = response.json()\n",
    "print(f\"Total available records: {data['meta']['total']}\")\n",
    "print(f\"Records returned: {len(data['results'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect Complete Response Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at first record to see all fields\n",
    "if data['results']:\n",
    "    sample_record = data['results'][0]\n",
    "    print(\"Complete field structure:\")\n",
    "    print(json.dumps(sample_record, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract All Top-Level Field Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_fields(records: List[Dict]) -> Dict[str, type]:\n",
    "    \"\"\"\n",
    "    Extract all unique field names and their types from a list of records.\n",
    "    \"\"\"\n",
    "    all_fields = {}\n",
    "    \n",
    "    for record in records:\n",
    "        for key, value in record.items():\n",
    "            if key not in all_fields:\n",
    "                all_fields[key] = type(value).__name__\n",
    "    \n",
    "    return all_fields\n",
    "\n",
    "field_types = get_all_fields(data['results'])\n",
    "print(\"\\nAll top-level fields found:\")\n",
    "for field, dtype in sorted(field_types.items()):\n",
    "    print(f\"  {field}: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inspect Nested Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organization structure\n",
    "if 'organization' in sample_record:\n",
    "    print(\"Organization fields:\")\n",
    "    print(json.dumps(sample_record['organization'], indent=2))\n",
    "\n",
    "# Principal Investigators\n",
    "if 'principal_investigators' in sample_record:\n",
    "    print(\"\\nPrincipal Investigators structure:\")\n",
    "    if sample_record['principal_investigators']:\n",
    "        print(json.dumps(sample_record['principal_investigators'][0], indent=2))\n",
    "\n",
    "# Program Officers\n",
    "if 'program_officers' in sample_record:\n",
    "    print(\"\\nProgram Officers structure:\")\n",
    "    if sample_record['program_officers']:\n",
    "        print(json.dumps(sample_record['program_officers'][0], indent=2))\n",
    "\n",
    "# Study Section\n",
    "if 'full_study_section' in sample_record:\n",
    "    print(\"\\nStudy Section structure:\")\n",
    "    print(json.dumps(sample_record['full_study_section'], indent=2))\n",
    "\n",
    "# Agency IC Admin\n",
    "if 'agency_ic_admin' in sample_record:\n",
    "    print(\"\\nAgency IC Admin structure:\")\n",
    "    print(json.dumps(sample_record['agency_ic_admin'], indent=2))\n",
    "\n",
    "# Publications\n",
    "if 'publications' in sample_record:\n",
    "    print(\"\\nPublications structure:\")\n",
    "    if sample_record['publications']:\n",
    "        print(json.dumps(sample_record['publications'][0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test pagination with different offsets\n",
    "def test_pagination(fiscal_year: int, limit: int = 10):\n",
    "    \"\"\"\n",
    "    Test pagination by fetching multiple pages.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total = None\n",
    "    \n",
    "    for offset in [0, 10, 20]:\n",
    "        payload = {\n",
    "            'criteria': {'fiscal_years': [fiscal_year]},\n",
    "            'offset': offset,\n",
    "            'limit': limit\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "            f'{API_BASE_URL}{API_ENDPOINT}',\n",
    "            json=payload,\n",
    "            headers={'Content-Type': 'application/json'}\n",
    "        )\n",
    "        \n",
    "        data = response.json()\n",
    "        if total is None:\n",
    "            total = data['meta']['total']\n",
    "        \n",
    "        print(f\"Offset {offset}: Retrieved {len(data['results'])} records\")\n",
    "        results.extend(data['results'])\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    print(f\"\\nTotal available: {total}\")\n",
    "    print(f\"Total retrieved: {len(results)}\")\n",
    "    return results\n",
    "\n",
    "pagination_test = test_pagination(2024, limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Different Query Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different criteria to see field variations\n",
    "test_queries = [\n",
    "    {\n",
    "        'name': 'By IC',\n",
    "        'criteria': {\n",
    "            'fiscal_years': [2024],\n",
    "            'agencies': ['NCI']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'By Organization',\n",
    "        'criteria': {\n",
    "            'fiscal_years': [2024],\n",
    "            'org_names': ['HARVARD']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'With Publications',\n",
    "        'criteria': {\n",
    "            'fiscal_years': [2024],\n",
    "            'include_active_projects': True\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    payload = {\n",
    "        'criteria': query['criteria'],\n",
    "        'offset': 0,\n",
    "        'limit': 5\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        f'{API_BASE_URL}{API_ENDPOINT}',\n",
    "        json=payload,\n",
    "        headers={'Content-Type': 'application/json'}\n",
    "    )\n",
    "    \n",
    "    data = response.json()\n",
    "    print(f\"\\n{query['name']}: {data['meta']['total']} total records\")\n",
    "    \n",
    "    time.sleep(RATE_LIMIT_DELAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Field Coverage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze field coverage across multiple records\n",
    "def analyze_field_coverage(records: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze which fields are populated across records.\n",
    "    \"\"\"\n",
    "    field_stats = {}\n",
    "    total_records = len(records)\n",
    "    \n",
    "    for record in records:\n",
    "        for key, value in record.items():\n",
    "            if key not in field_stats:\n",
    "                field_stats[key] = {\n",
    "                    'count': 0,\n",
    "                    'null_count': 0,\n",
    "                    'type': type(value).__name__\n",
    "                }\n",
    "            \n",
    "            if value is not None and value != '' and value != []:\n",
    "                field_stats[key]['count'] += 1\n",
    "            else:\n",
    "                field_stats[key]['null_count'] += 1\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame.from_dict(field_stats, orient='index')\n",
    "    df['coverage_%'] = (df['count'] / total_records * 100).round(2)\n",
    "    df = df.sort_values('coverage_%', ascending=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Fetch more records for better coverage analysis\n",
    "large_payload = {\n",
    "    'criteria': {'fiscal_years': [2024]},\n",
    "    'offset': 0,\n",
    "    'limit': 100\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f'{API_BASE_URL}{API_ENDPOINT}',\n",
    "    json=large_payload,\n",
    "    headers={'Content-Type': 'application/json'}\n",
    ")\n",
    "\n",
    "large_data = response.json()\n",
    "coverage_df = analyze_field_coverage(large_data['results'])\n",
    "\n",
    "print(\"Field Coverage Analysis (100 records):\")\n",
    "print(coverage_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Generate Field Mapping Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_field_documentation(records: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Generate markdown documentation of all fields.\n",
    "    \"\"\"\n",
    "    all_fields = {}\n",
    "    \n",
    "    for record in records:\n",
    "        def extract_fields(obj, prefix=''):\n",
    "            if isinstance(obj, dict):\n",
    "                for key, value in obj.items():\n",
    "                    field_name = f\"{prefix}.{key}\" if prefix else key\n",
    "                    all_fields[field_name] = type(value).__name__\n",
    "                    \n",
    "                    if isinstance(value, dict):\n",
    "                        extract_fields(value, field_name)\n",
    "                    elif isinstance(value, list) and value and isinstance(value[0], dict):\n",
    "                        extract_fields(value[0], f\"{field_name}[]\")\n",
    "        \n",
    "        extract_fields(record)\n",
    "    \n",
    "    # Generate markdown\n",
    "    md = \"# NIH RePORTER API Fields\\n\\n\"\n",
    "    md += \"| Field Name | Data Type |\\n\"\n",
    "    md += \"|------------|-----------|\\n\"\n",
    "    \n",
    "    for field, dtype in sorted(all_fields.items()):\n",
    "        md += f\"| `{field}` | {dtype} |\\n\"\n",
    "    \n",
    "    return md\n",
    "\n",
    "field_docs = generate_field_documentation(large_data['results'])\n",
    "print(field_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test Rate Limiting Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test rapid requests to understand rate limiting\n",
    "def test_rate_limiting(num_requests: int = 5):\n",
    "    \"\"\"\n",
    "    Test API rate limiting behavior.\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        'criteria': {'fiscal_years': [2024]},\n",
    "        'offset': 0,\n",
    "        'limit': 1\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(num_requests):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = requests.post(\n",
    "            f'{API_BASE_URL}{API_ENDPOINT}',\n",
    "            json=payload,\n",
    "            headers={'Content-Type': 'application/json'}\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        results.append({\n",
    "            'request': i + 1,\n",
    "            'status_code': response.status_code,\n",
    "            'elapsed_time': f\"{elapsed:.3f}s\"\n",
    "        })\n",
    "        \n",
    "        print(f\"Request {i+1}: Status {response.status_code}, Time {elapsed:.3f}s\")\n",
    "        \n",
    "        # Wait before next request\n",
    "        time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Uncomment to test (will make multiple API calls)\n",
    "# rate_limit_df = test_rate_limiting(5)\n",
    "# print(rate_limit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary and Recommendations\n",
    "\n",
    "Based on this exploration:\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **API Response Structure**: \n",
    "   - Meta object with total count\n",
    "   - Results array with project records\n",
    "   - Consistent JSON structure\n",
    "\n",
    "2. **Pagination**:\n",
    "   - Max 500 records per request\n",
    "   - Max offset of 14,999\n",
    "   - Need to refine queries for >15,000 records\n",
    "\n",
    "3. **Rate Limiting**:\n",
    "   - Recommended 1 second delay between requests\n",
    "   - Returns 429 if exceeded\n",
    "\n",
    "4. **Field Coverage**:\n",
    "   - 100+ unique fields across nested structures\n",
    "   - Some fields have sparse data (publications, clinical trials)\n",
    "   - Array fields require special handling\n",
    "\n",
    "### Pipeline Design Recommendations\n",
    "\n",
    "1. **Bronze Layer**: Store complete raw JSON to ensure no data loss\n",
    "2. **Silver Layer**: Create normalized tables for:\n",
    "   - dim_projects\n",
    "   - dim_organizations\n",
    "   - dim_personnel\n",
    "   - fact_funding\n",
    "   - bridge_publications\n",
    "   - bridge_clinical_trials\n",
    "3. **Incremental Processing**: Use fiscal_year partitioning\n",
    "4. **Error Handling**: Implement retry logic for rate limits\n",
    "5. **Monitoring**: Track API response times and data volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
